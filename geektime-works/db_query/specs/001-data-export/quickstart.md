# Quickstart Guide: æ•°æ®å¯¼å‡ºåŠŸèƒ½æ¨¡å—

**Feature**: æ•°æ®å¯¼å‡ºåŠŸèƒ½æ¨¡å—
**Branch**: `001-data-export`
**Last Updated**: 2025-12-28

## Overview

æœ¬æŒ‡å—æä¾›æ•°æ®å¯¼å‡ºåŠŸèƒ½çš„å¿«é€Ÿå¼€å§‹è¯´æ˜,åŒ…æ‹¬å¼€å‘ç¯å¢ƒè®¾ç½®ã€æ ¸å¿ƒæ¦‚å¿µã€å¸¸è§ä½¿ç”¨åœºæ™¯å’Œæ•…éšœæ’æŸ¥ã€‚

---

## Prerequisites

### Required Software

- **Python**: 3.12+
- **Node.js**: 18+
- **Database**: PostgreSQL 12+ æˆ– MySQL 8+
- **OpenAI API Key**: ç”¨äº AI å¯¼å‡ºåŠ©æ‰‹åŠŸèƒ½

### Check Your Environment

```bash
# Python ç‰ˆæœ¬
python --version  # åº”æ˜¾ç¤º 3.12+

# Node.js ç‰ˆæœ¬
node --version  # åº”æ˜¾ç¤º 18+

# éªŒè¯æ•°æ®åº“è¿æ¥
psql --version  # PostgreSQL
# æˆ–
mysql --version  # MySQL
```

---

## Setup

### 1. Install Dependencies

```bash
# å®‰è£…åç«¯ä¾èµ–
cd backend
uv sync

# å®‰è£…å‰ç«¯ä¾èµ–
cd ../frontend
npm install
```

### 2. Configure Environment

ç¼–è¾‘ `backend/.env`:

```bash
# æ•°æ®åº“è¿æ¥(åº”ç”¨æ•°æ®åº“)
DATABASE_URL=postgresql://user:password@localhost:5432/db_query

# OpenAI API Key(ç”¨äº AI å¯¼å‡ºåŠ©æ‰‹)
OPENAI_API_KEY=sk-...

# CORS è®¾ç½®(å¼€å‘ç¯å¢ƒ)
CORS_ORIGINS=http://localhost:5173

# æ–‡ä»¶å¯¼å‡ºé…ç½®
EXPORT_MAX_FILE_SIZE_MB=100
EXPORT_TIMEOUT_SECONDS=300
EXPORT_MAX_CONCURRENT_PER_USER=3
```

ç¼–è¾‘ `frontend/.env.local`:

```bash
# API ç«¯ç‚¹
VITE_API_BASE_URL=http://localhost:8000
```

### 3. Initialize Database

```bash
cd backend

# åº”ç”¨æ•°æ®åº“è¿ç§»
uv run alembic upgrade head

# éªŒè¯è¿ç§»
uv run alembic current
```

### 4. Start Development Servers

```bash
# æ–¹å¼ 1: ä½¿ç”¨ Make(æ¨è)
make dev  # åŒæ—¶å¯åŠ¨å‰åç«¯

# æ–¹å¼ 2: æ‰‹åŠ¨å¯åŠ¨
# ç»ˆç«¯ 1: å¯åŠ¨åç«¯
cd backend && uv run uvicorn app.main:app --reload --port 8000

# ç»ˆç«¯ 2: å¯åŠ¨å‰ç«¯
cd frontend && npm run dev
```

### 5. Verify Setup

```bash
# åç«¯å¥åº·æ£€æŸ¥
curl http://localhost:8000/health
# é¢„æœŸè¾“å‡º: {"status": "healthy"}

# æŸ¥çœ‹ API æ–‡æ¡£
open http://localhost:8000/docs
```

---

## Core Concepts

### 1. Export Task Lifecycle

```
åˆ›å»ºä»»åŠ¡ â†’ pending â†’ running â†’ completed â†’ ä¸‹è½½æ–‡ä»¶
                â†“         â†“
             cancelled  failed
```

### 2. Export Formats

| æ ¼å¼ | MIME ç±»å‹ | é€‚ç”¨åœºæ™¯ |
|------|-----------|----------|
| **CSV** | `text/csv; charset=utf-8-sig` | Excel å…¼å®¹,æ•°æ®åˆ†æ |
| **JSON** | `application/json; charset=utf-8` | Web åº”ç”¨,API é›†æˆ |
| **Markdown** | `text/markdown; charset=utf-8` | æ–‡æ¡£,æŠ¥å‘Š |

### 3. Export Scope

- **Current Page**: ä»…å¯¼å‡ºå½“å‰æŸ¥è¯¢ç»“æœ(å— LIMIT 1000 é™åˆ¶)
- **All Data**: å¯¼å‡ºæ‰€æœ‰æ•°æ®(ç§»é™¤ LIMIT é™åˆ¶,éœ€è°¨æ…)

### 4. Concurrency Limits

- å•ç”¨æˆ·æœ€å¤šåŒæ—¶è¿›è¡Œ **3 ä¸ª**å¯¼å‡ºä»»åŠ¡
- è¶…è¿‡é™åˆ¶æ—¶è¿”å› `429 Too Many Requests`

### 5. File Size Limits

- æœ€å¤§æ–‡ä»¶å¤§å°: **100MB**
- é¢„ä¼°è¶…è¿‡é™åˆ¶æ—¶é˜»æ­¢å¯¼å‡º
- æ¥è¿‘é™åˆ¶(>80MB)æ—¶æ˜¾ç¤ºè­¦å‘Š

---

## Common Use Cases

### Use Case 1: æ‰‹åŠ¨å¯¼å‡ºæŸ¥è¯¢ç»“æœ

**åœºæ™¯**: ç”¨æˆ·æ‰§è¡ŒæŸ¥è¯¢å,æ‰‹åŠ¨å¯¼å‡ºä¸º CSV æ–‡ä»¶ã€‚

**æ­¥éª¤**:

1. **æ‰§è¡ŒæŸ¥è¯¢**:
   ```sql
   SELECT * FROM users LIMIT 1000
   ```

2. **ç‚¹å‡»å¯¼å‡ºæŒ‰é’®**:
   ```typescript
   // å‰ç«¯ä»£ç 
   const handleExport = async () => {
     await exportQueryResult(
       'postgres_db',           // æ•°æ®åº“åç§°
       'SELECT * FROM users',   // SQL
       'csv',                   // æ ¼å¼
       false                    // exportAll=false (å½“å‰é¡µ)
     );
   };
   ```

3. **è½®è¯¢è¿›åº¦**:
   ```typescript
   const pollProgress = async (taskId: string) => {
     const task = await getTaskStatus(taskId);

     if (task.status === 'completed') {
       // ä¸‹è½½æ–‡ä»¶
       window.location.href = task.fileUrl;
     } else if (task.status === 'running') {
       // æ›´æ–°è¿›åº¦æ¡
       updateProgressBar(task.progress);
       // ç»§ç»­è½®è¯¢
       setTimeout(() => pollProgress(taskId), 1000);
     }
   };
   ```

4. **æ–‡ä»¶ä¸‹è½½**:
   - æ–‡ä»¶åæ ¼å¼: `export-<uuid>.csv`
   - ç¤ºä¾‹: `export-a1b2c3d4-e5f6-7890-abcd-ef1234567890.csv`

**åç«¯ API è°ƒç”¨**:
```bash
curl -X POST "http://localhost:8000/api/v1/dbs/postgres_db/export" \
  -H "Content-Type: application/json" \
  -d '{
    "sql": "SELECT * FROM users LIMIT 1000",
    "format": "csv",
    "exportAll": false
  }'

# å“åº”:
# {
#   "taskId": "a1b2c3d4-...",
#   "status": "pending",
#   "progress": 0
# }
```

---

### Use Case 2: æ£€æŸ¥æ–‡ä»¶å¤§å°åå†å¯¼å‡º

**åœºæ™¯**: å¯¼å‡ºå‰é¢„ä¼°æ–‡ä»¶å¤§å°,é¿å…è¶…è¿‡é™åˆ¶ã€‚

**æ­¥éª¤**:

1. **è°ƒç”¨æ–‡ä»¶å¤§å°æ£€æŸ¥ API**:
   ```bash
   curl -X POST "http://localhost:8000/api/v1/dbs/postgres_db/export/check" \
     -H "Content-Type: application/json" \
     -d '{
       "sql": "SELECT * FROM large_table",
       "format": "csv",
       "useSampling": true
     }'
   ```

2. **è§£æå“åº”**:
   ```json
   {
     "allowed": true,
     "estimatedSize": {
       "estimatedBytes": 89478485,
       "estimatedMb": 85.3,
       "bytesPerRow": 875,
       "method": "sample",
       "confidence": "high"
     },
     "warning": "é¢„ä¼°æ–‡ä»¶å¤§å° 85.3MB æ¥è¿‘é™åˆ¶",
     "recommendation": "å»ºè®®ä½¿ç”¨é‡‡æ ·è·å–æ›´å‡†ç¡®çš„ä¼°ç®—,æˆ–å‡å°‘å¯¼å‡ºæ•°æ®é‡"
   }
   ```

3. **å†³å®šæ˜¯å¦å¯¼å‡º**:
   - `allowed: true` â†’ å¯ä»¥å¯¼å‡º
   - `allowed: false` â†’ é˜»æ­¢å¯¼å‡º,æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
   - `warning` ä¸ä¸ºç©º â†’ æ˜¾ç¤ºè­¦å‘Š,ç”¨æˆ·ç¡®è®¤åå¯¼å‡º

---

### Use Case 3: AI ä¸»åŠ¨å»ºè®®å¯¼å‡º

**åœºæ™¯**: æŸ¥è¯¢å®Œæˆå,AI åŠ©æ‰‹ä¸»åŠ¨è¯¢é—®æ˜¯å¦éœ€è¦å¯¼å‡ºã€‚

**æ­¥éª¤**:

1. **å‰ç«¯é›†æˆ AI å»ºè®®ç»„ä»¶**:
   ```typescript
   import { useAIExportSuggestion } from '@/hooks/useAIExportSuggestion';

   export const QueryResultTable = () => {
     const { analyzeIntent, suggestion } = useAIExportSuggestion();

     useEffect(() => {
       // æŸ¥è¯¢å®Œæˆåè‡ªåŠ¨åˆ†æ
       if (queryResult) {
         analyzeIntent({
           databaseName: 'postgres_db',
           sqlText: queryResult.sql,
           rowCount: queryResult.rowCount,
           executionTimeMs: queryResult.executionTimeMs,
         });
       }
     }, [queryResult]);

     return (
       <>
         <Table data={queryResult.rows} />

         {suggestion?.shouldSuggestExport && (
           <Alert
             message={suggestion.reason}
             action={
               <Button onClick={() => handleExport(suggestion.suggestedFormat)}>
                 å¯¼å‡ºä¸º {suggestion.suggestedFormat.toUpperCase()}
               </Button>
             }
           />
         )}
       </>
     );
   };
   ```

2. **åç«¯ API è°ƒç”¨**:
   ```bash
   curl -X POST "http://localhost:8000/api/v1/export/analyze-intent" \
     -H "Content-Type: application/json" \
     -d '{
       "databaseName": "postgres_db",
       "sqlText": "SELECT * FROM orders WHERE order_date >= '\''2025-01-01'\''",
       "rowCount": 1500,
       "executionTimeMs": 250
     }'
   ```

3. **AI å“åº”**:
   ```json
   {
     "shouldSuggestExport": true,
     "confidence": "high",
     "reason": "å‘ç°1500æ¡2025å¹´è®¢å•æ•°æ®,å»ºè®®å¯¼å‡ºä¸ºCSVè¿›è¡Œè´¢åŠ¡åˆ†æ",
     "suggestedFormat": "csv",
     "suggestedScope": "all_data",
     "clarificationQuestion": null
   }
   ```

---

### Use Case 4: AI ç”Ÿæˆå¯¼å‡º SQL

**åœºæ™¯**: ç”¨æˆ·æè¿°éœ€æ±‚,AI è‡ªåŠ¨ç”Ÿæˆä¼˜åŒ–çš„å¯¼å‡º SQLã€‚

**æ­¥éª¤**:

1. **å‰ç«¯è¾“å…¥ç”¨æˆ·éœ€æ±‚**:
   ```typescript
   const handleGenerateSQL = async (userPrompt: string) => {
     const result = await generateExportSQL({
       databaseName: 'postgres_db',
       userPrompt: 'å¯¼å‡ºä¸Šä¸ªæœˆé”€å”®é¢æœ€é«˜çš„å‰10ä¸ªäº§å“',
       dbType: 'postgresql',
       formatHint: 'csv',
     });

     setGeneratedSQL(result.sql);
     setExplanation(result.explanation);
   };
   ```

2. **åç«¯ API è°ƒç”¨**:
   ```bash
   curl -X POST "http://localhost:8000/api/v1/export/generate-sql" \
     -H "Content-Type: application/json" \
     -d '{
       "databaseName": "postgres_db",
       "userPrompt": "å¯¼å‡ºä¸Šä¸ªæœˆé”€å”®é¢æœ€é«˜çš„å‰10ä¸ªäº§å“",
       "dbType": "postgresql",
       "formatHint": "csv"
     }'
   ```

3. **AI ç”Ÿæˆçš„ SQL**:
   ```json
   {
     "sql": "SELECT p.name, SUM(o.quantity) as total_sold, SUM(o.quantity * p.price) as revenue FROM products p JOIN orders o ON p.id = o.product_id WHERE o.order_date >= NOW() - INTERVAL '\''1 month'\'' GROUP BY p.id, p.name ORDER BY revenue DESC LIMIT 10",
     "explanation": "ä»è®¢å•è¡¨ä¸­ç­›é€‰æœ€è¿‘ä¸€ä¸ªæœˆçš„æ•°æ®,æŒ‰äº§å“åˆ†ç»„ç»Ÿè®¡é”€å”®é¢,æŒ‰æ”¶å…¥é™åºæ’åˆ—",
     "estimatedRows": 10,
     "performanceTips": [
       "å·²åœ¨ order_date ä¸Šåˆ›å»ºç´¢å¼•å¯åŠ é€ŸæŸ¥è¯¢",
       "è€ƒè™‘æ·»åŠ  WHERE o.status = '\''completed'\'' ä»…ç»Ÿè®¡å·²å®Œæˆè®¢å•"
     ],
     "warnings": [
       "å¦‚æœè®¢å•è¡¨æ•°æ®é‡å·¨å¤§(>100ä¸‡è¡Œ),å»ºè®®å…ˆé¢„ä¼°æŸ¥è¯¢æ—¶é—´"
     ]
   }
   ```

---

## Testing

### Backend Tests

```bash
cd backend

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
uv run pytest

# è¿è¡Œå¯¼å‡ºç›¸å…³æµ‹è¯•
uv run pytest tests/test_export.py -v

# è¿è¡Œ API æµ‹è¯•
uv run pytest tests/test_api_export.py -v
```

### Frontend Tests

```bash
cd frontend

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
npm run test

# è¿è¡Œå¯¼å‡ºç»„ä»¶æµ‹è¯•
npm run test -- src/components/export
```

### Manual Testing

ä½¿ç”¨ VSCode REST Client æ‰©å±•æµ‹è¯• `fixtures/test.rest`:

```http
### åˆ›å»ºå¯¼å‡ºä»»åŠ¡
POST http://localhost:8000/api/v1/dbs/postgres_db/export
Content-Type: application/json

{
  "sql": "SELECT * FROM users LIMIT 100",
  "format": "csv",
  "exportAll": false
}

### æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
GET http://localhost:8000/api/v1/tasks/{{taskId}}

### ä¸‹è½½å¯¼å‡ºæ–‡ä»¶
GET http://localhost:8000/api/v1/exports/download/export-{{uuid}}.csv
```

---

## Troubleshooting

### Problem: å¯¼å‡ºæ–‡ä»¶ä¸­æ–‡ä¹±ç 

**ç—‡çŠ¶**: Excel æ‰“å¼€ CSV æ–‡ä»¶æ—¶ä¸­æ–‡æ˜¾ç¤ºä¸ºä¹±ç ã€‚

**åŸå› **: Excel éœ€è¦å¸¦ BOM çš„ UTF-8 ç¼–ç ã€‚

**è§£å†³æ–¹æ¡ˆ**:
- åç«¯å·²ä½¿ç”¨ `utf-8-sig` ç¼–ç (å¸¦ BOM)
- ç¡®ä¿å‰ç«¯ä¸‹è½½æ—¶æœªæ›´æ”¹ç¼–ç 
- Excel ä¸­ä½¿ç”¨"æ•°æ® â†’ ä»æ–‡æœ¬/CSVå¯¼å…¥"åŠŸèƒ½

---

### Problem: å¯¼å‡ºä»»åŠ¡ä¸€ç›´å¤„äº pending çŠ¶æ€

**ç—‡çŠ¶**: ä»»åŠ¡åˆ›å»ºåè¿›åº¦å§‹ç»ˆä¸º 0,status ä¸€ç›´æ˜¯ `pending`ã€‚

**åŸå› **: åå° worker æœªå¯åŠ¨æˆ–å´©æºƒã€‚

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥åç«¯æ—¥å¿—
cd backend
tail -f logs/app.log

# é‡å¯åç«¯æœåŠ¡
uv run uvicorn app.main:app --reload

# æ£€æŸ¥ TaskManager æ˜¯å¦åˆå§‹åŒ–
# åœ¨ app/main.py ä¸­ç¡®è®¤:
# task_manager = TaskManager.get_instance()
# await task_manager.start_worker()
```

---

### Problem: å¹¶å‘é™åˆ¶ä¸ç”Ÿæ•ˆ

**ç—‡çŠ¶**: å•ç”¨æˆ·å¯ä»¥åŒæ—¶å¯åŠ¨è¶…è¿‡ 3 ä¸ªå¯¼å‡ºä»»åŠ¡ã€‚

**åŸå› **: ç”¨æˆ·æ ‡è¯†ç¬¦æœªæ­£ç¡®ä¼ é€’æˆ–è¯†åˆ«ã€‚

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç¡®ä¿è¯·æ±‚å¤´åŒ…å«ç”¨æˆ·æ ‡è¯†
# å‰ç«¯:
headers: {
  'X-User-ID': 'user-123'
}

# åç«¯ API:
def get_user_id(x_user_id: str = Header(..., alias="X-User-ID")) -> str:
    return x_user_id
```

---

### Problem: AI å»ºè®®ä¸æ˜¾ç¤º

**ç—‡çŠ¶**: æŸ¥è¯¢å®Œæˆåæ²¡æœ‰çœ‹åˆ° AI å¯¼å‡ºå»ºè®®ã€‚

**åŸå› **:
1. AI åˆ†æå¤±è´¥(æ£€æŸ¥ `OPENAI_API_KEY`)
2. æŸ¥è¯¢ç»“æœä¸ç¬¦åˆå»ºè®®æ¡ä»¶(å¦‚è¡Œæ•°å¤ªå°‘)
3. AI åŠ©æ‰‹å¼€å…³æœªå¼€å¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# éªŒè¯ OpenAI API Key
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models

# æ£€æŸ¥ AI åŠ©æ‰‹è®¾ç½®
# å‰ç«¯ localStorage: aiAssistantEnabled = true

# æŸ¥çœ‹åç«¯æ—¥å¿—
tail -f backend/logs/app.log | grep "AI"
```

---

### Problem: æ–‡ä»¶å¤§å°ä¼°ç®—ä¸å‡†ç¡®

**ç—‡çŠ¶**: å®é™…æ–‡ä»¶å¤§å°ä¸é¢„ä¼°å·®å¼‚å¾ˆå¤§(>50%)ã€‚

**åŸå› **:
1. ä½¿ç”¨å…ƒæ•°æ®ä¼°ç®—(å‡†ç¡®æ€§è¾ƒä½)
2. æ•°æ®åˆ†å¸ƒä¸å‡åŒ€
3. åŒ…å«å˜é•¿å­—æ®µ(å¦‚ TEXT)

**è§£å†³æ–¹æ¡ˆ**:
```typescript
// ä½¿ç”¨é‡‡æ ·ç²¾ç¡®ä¼°ç®—
const checkResult = await checkExportSize({
  sql: querySQL,
  format: 'csv',
  useSampling: true,  // å¯ç”¨é‡‡æ ·
  sampleSize: 500,    // å¢åŠ é‡‡æ ·é‡
});
```

---

## Performance Tips

### 1. ä¼˜åŒ–å¯¼å‡ºæ€§èƒ½

```python
# æ‰¹é‡å¤„ç†å¤§å°è°ƒæ•´
BATCH_SIZE = 1000  # é»˜è®¤å€¼

# å¯¹äºå¿«é€Ÿç½‘ç»œ: å¢å¤§æ‰¹å¤„ç†
BATCH_SIZE = 5000

# å¯¹äºæ…¢é€Ÿç½‘ç»œ: å‡å°æ‰¹å¤„ç†
BATCH_SIZE = 500
```

### 2. å‡å°‘å†…å­˜å ç”¨

```python
# ä½¿ç”¨æµå¼å“åº”(å·²é»˜è®¤å®ç°)
StreamingResponse(generate_csv(), media_type="text/csv")

# é¿å…ä¸€æ¬¡æ€§åŠ è½½å…¨éƒ¨æ•°æ®
# âŒ é”™è¯¯:
rows = await fetch_all_rows()  # å…¨éƒ¨åŠ è½½åˆ°å†…å­˜

# âœ… æ­£ç¡®:
async for batch in fetch_batches(batch_size=1000):
    yield serialize_batch(batch)
```

### 3. æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–

```sql
-- æ·»åŠ ç´¢å¼•åŠ é€Ÿå¯¼å‡º
CREATE INDEX idx_order_date ON orders(order_date);

-- é¿å…å¯¼å‡ºä¸å¿…è¦çš„åˆ—
SELECT col1, col2, col3 FROM table  -- âœ…
SELECT * FROM table  -- âŒ (åŒ…å«ä¸éœ€è¦çš„åˆ—)

-- ä½¿ç”¨ WHERE å‡å°‘æ•°æ®é‡
SELECT * FROM large_table WHERE status = 'active'  -- âœ…
```

---

## Next Steps

1. **é˜…è¯»å®Œæ•´æ–‡æ¡£**:
   - [æ•°æ®æ¨¡å‹](./data-model.md)
   - [API è§„èŒƒ](./contracts/api-v1.yaml)
   - [ç ”ç©¶æŠ¥å‘Š](./research.md)

2. **è¿è¡Œé›†æˆæµ‹è¯•**:
   ```bash
   make test-backend
   make test-frontend
   ```

3. **æŸ¥çœ‹ç¤ºä¾‹ä»£ç **:
   - åç«¯: `backend/app/services/export.py`
   - å‰ç«¯: `frontend/src/components/export/`

4. **æäº¤ PR**:
   - ç¡®ä¿æ‰€æœ‰æµ‹è¯•é€šè¿‡
   - ä»£ç å·²æ ¼å¼åŒ– (`make format`)
   - æ›´æ–°æ–‡æ¡£

---

## Getting Help

- **æ–‡æ¡£**: æŸ¥çœ‹ `CLAUDE.md` å’Œ `docs/` ç›®å½•
- **Issues**: åœ¨ GitHub ä¸Šæäº¤ issue
- **æ—¥å¿—**: æ£€æŸ¥ `backend/logs/app.log`
- **API æ–‡æ¡£**: è®¿é—® http://localhost:8000/docs

---

**Happy Exporting! ğŸš€**
