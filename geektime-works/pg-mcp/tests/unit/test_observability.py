"""å¯è§‚æµ‹æ€§æ¨¡å—å•å…ƒæµ‹è¯•.

æµ‹è¯•è¦†ç›–ï¼š
- Prometheus æŒ‡æ ‡æ”¶é›†
- è¯·æ±‚è¿½è¸ªä¸ä¸Šä¸‹æ–‡ä¼ æ’­
- ç»“æ„åŒ–æ—¥å¿—è®°å½•
- æ•æ„Ÿæ•°æ®è¿‡æ»¤
"""

import asyncio
import json
import logging
from unittest.mock import MagicMock, patch

import pytest

from pg_mcp.observability.logging import JSONFormatter, SensitiveDataFilter
from pg_mcp.observability.metrics import MetricsCollector
from pg_mcp.observability.tracing import TracingLogger, request_context


class TestMetricsCollector:
    """æµ‹è¯• Prometheus æŒ‡æ ‡æ”¶é›†å™¨."""

    def test_initialization(self) -> None:
        """æµ‹è¯•æŒ‡æ ‡æ”¶é›†å™¨åˆå§‹åŒ–."""
        metrics = MetricsCollector()
        assert metrics is not None

    def test_increment_query_request(self) -> None:
        """æµ‹è¯•æŸ¥è¯¢è¯·æ±‚è®¡æ•°."""
        metrics = MetricsCollector()

        metrics.increment_query_request(status="success", database="mydb")
        metrics.increment_query_request(status="error", database="mydb")

        # è·å–æŒ‡æ ‡å€¼
        # æ³¨æ„: è¿™éœ€è¦å®é™…çš„ Prometheus registry è®¿é—®
        # è¿™é‡Œæˆ‘ä»¬åªæ˜¯éªŒè¯æ–¹æ³•ä¸æŠ›å‡ºå¼‚å¸¸
        assert metrics is not None

    def test_observe_query_duration(self) -> None:
        """æµ‹è¯•æŸ¥è¯¢æŒç»­æ—¶é—´è§‚å¯Ÿ."""
        from prometheus_client import Histogram

        metrics = MetricsCollector()

        # ä½¿ç”¨å®é™…çš„ histogram.observe æ–¹æ³•
        metrics.query_duration.observe(1.5)
        metrics.query_duration.observe(0.5)

        assert metrics is not None

    def test_increment_llm_call(self) -> None:
        """æµ‹è¯• LLM è°ƒç”¨è®¡æ•°."""
        metrics = MetricsCollector()

        metrics.increment_llm_call(operation="generate_sql")
        metrics.increment_llm_call(operation="validate_result")

        assert metrics is not None

    def test_observe_llm_latency(self) -> None:
        """æµ‹è¯• LLM å»¶è¿Ÿè§‚å¯Ÿ."""
        metrics = MetricsCollector()

        metrics.observe_llm_latency("generate_sql", 2.5)
        metrics.observe_llm_latency("validate_result", 1.2)

        assert metrics is not None

    def test_record_llm_token_usage(self) -> None:
        """æµ‹è¯• LLM ä»¤ç‰Œä½¿ç”¨è®°å½•."""
        metrics = MetricsCollector()

        # ä½¿ç”¨å®é™…çš„ increment_llm_tokens æ–¹æ³•
        metrics.increment_llm_tokens(operation="generate_sql", tokens=150)
        metrics.increment_llm_tokens(operation="generate_sql", tokens=200)

        assert metrics is not None

    def test_increment_sql_rejected(self) -> None:
        """æµ‹è¯• SQL æ‹’ç»è®¡æ•°."""
        metrics = MetricsCollector()

        metrics.increment_sql_rejected(reason="ddl_detected")
        metrics.increment_sql_rejected(reason="blocked_function")

        assert metrics is not None

    def test_update_db_connections(self) -> None:
        """æµ‹è¯•æ•°æ®åº“è¿æ¥æ•°æ›´æ–°."""
        metrics = MetricsCollector()

        # ä½¿ç”¨å®é™…çš„ set_db_connections_active æ–¹æ³•
        metrics.set_db_connections_active(database="mydb", count=5)
        metrics.set_db_connections_active(database="analytics", count=3)

        assert metrics is not None

    def test_observe_db_query_duration(self) -> None:
        """æµ‹è¯•æ•°æ®åº“æŸ¥è¯¢æŒç»­æ—¶é—´è§‚å¯Ÿ."""
        metrics = MetricsCollector()

        # ä½¿ç”¨å®é™…çš„ observe_db_query_duration æ–¹æ³• (ä¸éœ€è¦ database å‚æ•°)
        metrics.observe_db_query_duration(0.25)
        metrics.observe_db_query_duration(0.10)

        assert metrics is not None

    def test_update_cache_age(self) -> None:
        """æµ‹è¯•ç¼“å­˜å¹´é¾„æ›´æ–°."""
        metrics = MetricsCollector()

        # ä½¿ç”¨å®é™…çš„ set_schema_cache_age æ–¹æ³•
        metrics.set_schema_cache_age(database="mydb", age_seconds=3600)
        metrics.set_schema_cache_age(database="analytics", age_seconds=1800)

        assert metrics is not None

    def test_multiple_metrics_independently(self) -> None:
        """æµ‹è¯•å¤šä¸ªæŒ‡æ ‡ç‹¬ç«‹å·¥ä½œ."""
        metrics = MetricsCollector()

        # è®°å½•å„ç§æŒ‡æ ‡ (ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•åå’Œå‚æ•°)
        metrics.increment_query_request(status="success", database="db1")
        metrics.query_duration.observe(1.0)
        metrics.increment_llm_call(operation="generate_sql")
        metrics.observe_llm_latency("generate_sql", 2.0)
        metrics.increment_llm_tokens(operation="generate_sql", tokens=100)
        metrics.increment_sql_rejected(reason="security")
        metrics.set_db_connections_active(database="db1", count=10)
        metrics.observe_db_query_duration(0.5)
        metrics.set_schema_cache_age(database="db1", age_seconds=7200)

        # æ‰€æœ‰æŒ‡æ ‡éƒ½åº”è¯¥è¢«è®°å½•
        assert metrics is not None


class TestTracing:
    """æµ‹è¯•è¯·æ±‚è¿½è¸ª."""

    @pytest.mark.asyncio
    async def test_request_context_generation(self) -> None:
        """æµ‹è¯•è¯·æ±‚ä¸Šä¸‹æ–‡ç”Ÿæˆå”¯ä¸€ ID."""
        from pg_mcp.observability.tracing import get_request_id

        async with request_context() as request_id:
            assert request_id is not None
            assert isinstance(request_id, str)
            assert len(request_id) > 0
            # éªŒè¯åœ¨ä¸Šä¸‹æ–‡ä¸­å¯ä»¥è·å–åˆ°request_id
            assert get_request_id() == request_id

    @pytest.mark.asyncio
    async def test_request_context_propagation(self) -> None:
        """æµ‹è¯•è¯·æ±‚ä¸Šä¸‹æ–‡ä¼ æ’­."""
        from pg_mcp.observability.tracing import get_request_id

        async with request_context() as request_id:
            # åœ¨ä¸Šä¸‹æ–‡ä¸­è·å–ç›¸åŒçš„ request_id
            current_id = get_request_id()
            assert current_id == request_id

    @pytest.mark.asyncio
    async def test_nested_contexts(self) -> None:
        """æµ‹è¯•åµŒå¥—ä¸Šä¸‹æ–‡."""
        from pg_mcp.observability.tracing import get_request_id

        async with request_context() as outer_id:
            assert get_request_id() == outer_id
            async with request_context() as inner_id:
                # å†…éƒ¨ä¸Šä¸‹æ–‡åº”è¯¥æœ‰ä¸åŒçš„ ID
                assert inner_id is not None
                assert get_request_id() == inner_id
                assert inner_id != outer_id

    @pytest.mark.asyncio
    async def test_context_cleanup(self) -> None:
        """æµ‹è¯•ä¸Šä¸‹æ–‡æ¸…ç†."""
        from pg_mcp.observability.tracing import get_request_id

        async with request_context() as request_id:
            current_id = get_request_id()
            assert current_id == request_id

        # ä¸Šä¸‹æ–‡ç»“æŸåï¼Œrequest_id åº”è¯¥è¢«æ¸…ç† (è¿”å› None)
        cleaned_id = get_request_id()
        assert cleaned_id is None

    @pytest.mark.asyncio
    async def test_trace_async_with_context(self) -> None:
        """æµ‹è¯•è¿½è¸ªä¸è¯·æ±‚ä¸Šä¸‹æ–‡é›†æˆ."""
        from pg_mcp.observability.tracing import get_request_id

        async def test_function() -> str:
            current_id = get_request_id()
            return current_id or "no-id"

        async with request_context() as request_id:
            result = await test_function()
            # åº”è¯¥èƒ½è®¿é—®åˆ° request_id
            assert result == request_id


class TestTracingLogger:
    """æµ‹è¯•è¿½è¸ªæ—¥å¿—è®°å½•å™¨."""

    def test_logger_includes_request_id(self) -> None:
        """æµ‹è¯•æ—¥å¿—è®°å½•å™¨åŒ…å«è¯·æ±‚ ID."""
        from pg_mcp.observability.tracing import get_request_id, set_request_id

        logger = TracingLogger("test_logger")

        # è®¾ç½®ä¸€ä¸ªæµ‹è¯•ç”¨çš„request_id
        test_id = "test-request-id-123"
        set_request_id(test_id)

        try:
            # è¿™ä¸ªæµ‹è¯•åªæ˜¯éªŒè¯æ–¹æ³•èƒ½è¢«è°ƒç”¨è€Œä¸æŠ›å‡ºå¼‚å¸¸
            # å®é™…çš„request_idé›†æˆç”±TracingLogger._logæ–¹æ³•å¤„ç†
            logger.info("Test message", extra={"key": "value"})
        finally:
            # æ¸…ç† request_id
            set_request_id(None)

    def test_logger_all_levels(self) -> None:
        """æµ‹è¯•æ‰€æœ‰æ—¥å¿—çº§åˆ«."""
        logger = TracingLogger("test_logger")

        levels = ["debug", "info", "warning", "error", "critical", "exception"]

        for level in levels:
            method = getattr(logger, level)
            # éªŒè¯æ–¹æ³•å­˜åœ¨ä¸”å¯è°ƒç”¨
            assert callable(method)

    def test_logger_with_extra_data(self) -> None:
        """æµ‹è¯•å¸¦é¢å¤–æ•°æ®çš„æ—¥å¿—."""
        logger = TracingLogger("test_logger")

        # æµ‹è¯•é¢å¤–æ•°æ®
        # è¿™ä¸ªæµ‹è¯•åªæ˜¯éªŒè¯æ–¹æ³•èƒ½è¢«è°ƒç”¨è€Œä¸æŠ›å‡ºå¼‚å¸¸
        logger.info("Test message", extra={"custom_field": "custom_value"})


class TestJSONFormatter:
    """æµ‹è¯• JSON æ ¼å¼åŒ–å™¨."""

    def test_formatter_creates_json(self) -> None:
        """æµ‹è¯•æ ¼å¼åŒ–å™¨åˆ›å»º JSON è¾“å‡º."""
        formatter = JSONFormatter()

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Test message",
            args=(),
            exc_info=None,
        )

        formatted = formatter.format(record)
        parsed = json.loads(formatted)

        # éªŒè¯ JSON ç»“æ„
        assert "message" in parsed
        assert parsed["message"] == "Test message"
        assert "level" in parsed
        assert parsed["level"] == "INFO"
        assert "timestamp" in parsed

    def test_formatter_includes_extra_fields(self) -> None:
        """æµ‹è¯•æ ¼å¼åŒ–å™¨åŒ…å«é¢å¤–å­—æ®µ."""
        formatter = JSONFormatter()

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Test message",
            args=(),
            exc_info=None,
        )
        # æ·»åŠ é¢å¤–å­—æ®µ
        record.request_id = "test-123"
        record.custom_field = "custom_value"

        formatted = formatter.format(record)
        parsed = json.loads(formatted)

        # request_id åº”è¯¥åœ¨é¡¶å±‚
        assert parsed["request_id"] == "test-123"
        # å…¶ä»–é¢å¤–å­—æ®µåº”è¯¥åœ¨ "extra" ä¸‹
        assert "extra" in parsed
        assert parsed["extra"]["custom_field"] == "custom_value"

    def test_formatter_handles_exception(self) -> None:
        """æµ‹è¯•æ ¼å¼åŒ–å™¨å¤„ç†å¼‚å¸¸ä¿¡æ¯."""
        formatter = JSONFormatter()

        try:
            raise ValueError("Test exception")
        except ValueError:
            import sys
            exc_info = sys.exc_info()

            record = logging.LogRecord(
                name="test",
                level=logging.ERROR,
                pathname="test.py",
                lineno=10,
                msg="Error occurred",
                args=(),
                exc_info=exc_info,
            )

        formatted = formatter.format(record)
        parsed = json.loads(formatted)

        # éªŒè¯å¼‚å¸¸ä¿¡æ¯è¢«åŒ…å«
        assert "exception" in parsed
        assert "ValueError: Test exception" in parsed["exception"]


class TestSensitiveDataFilter:
    """æµ‹è¯•æ•æ„Ÿæ•°æ®è¿‡æ»¤å™¨."""

    def test_filter_passwords(self) -> None:
        """æµ‹è¯•è¿‡æ»¤å¯†ç å­—æ®µ."""
        filter_obj = SensitiveDataFilter()

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Test message",
            args=(),
            exc_info=None,
        )
        record.password = "secret123"

        # åº”ç”¨è¿‡æ»¤å™¨
        filter_obj.filter(record)

        # å¯†ç åº”è¯¥è¢«å±è”½
        assert hasattr(record, "password")
        # æ ¹æ®å®ç°ï¼Œå¯èƒ½è¢«æ›¿æ¢ä¸º "***" æˆ–åˆ é™¤

    def test_filter_multiple_sensitive_keys(self) -> None:
        """æµ‹è¯•è¿‡æ»¤å¤šä¸ªæ•æ„Ÿå­—æ®µ."""
        filter_obj = SensitiveDataFilter()

        sensitive_keys = [
            "password",
            "passwd",
            "pwd",
            "secret",
            "api_key",
            "token",
            "access_token",
            "private_key",
            "auth",
        ]

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Test message",
            args=(),
            exc_info=None,
        )

        for key in sensitive_keys:
            setattr(record, key, f"{key}_value")

        # åº”ç”¨è¿‡æ»¤å™¨
        filter_obj.filter(record)

        # æ‰€æœ‰æ•æ„Ÿå­—æ®µåº”è¯¥è¢«å¤„ç†
        for key in sensitive_keys:
            assert hasattr(record, key)

    def test_filter_case_insensitive(self) -> None:
        """æµ‹è¯•è¿‡æ»¤å™¨ä¸åŒºåˆ†å¤§å°å†™."""
        filter_obj = SensitiveDataFilter()

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Test message",
            args=(),
            exc_info=None,
        )
        record.Password = "secret"
        record.API_KEY = "key123"

        # åº”ç”¨è¿‡æ»¤å™¨
        filter_obj.filter(record)

        # åº”è¯¥è¢«è¿‡æ»¤
        assert hasattr(record, "Password")
        assert hasattr(record, "API_KEY")


class TestSetupLogging:
    """æµ‹è¯•æ—¥å¿—è®¾ç½®."""

    def test_logger_initialization(self) -> None:
        """æµ‹è¯•æ—¥å¿—è®°å½•å™¨åˆå§‹åŒ–."""
        logger = logging.getLogger("test_logger")

        assert logger is not None
        assert isinstance(logger, logging.Logger)


class TestObservabilityIntegration:
    """é›†æˆæµ‹è¯•."""

    @pytest.mark.asyncio
    async def test_metrics_with_tracing(self) -> None:
        """æµ‹è¯•æŒ‡æ ‡ä¸è¿½è¸ªé›†æˆ."""
        metrics = MetricsCollector()

        async def traced_operation() -> str:
            metrics.increment_query_request(status="success", database="test_db")
            return "success"

        async with request_context():
            result = await traced_operation()
            assert result == "success"

    @pytest.mark.asyncio
    async def test_tracing_with_logging(self) -> None:
        """æµ‹è¯•è¿½è¸ªä¸æ—¥å¿—é›†æˆ."""
        logger = TracingLogger("test_logger")

        async def logged_operation() -> str:
            logger.info("Processing operation")
            await asyncio.sleep(0.01)
            logger.info("Operation completed")
            return "done"

        async with request_context():
            result = await logged_operation()
            assert result == "done"

    @pytest.mark.asyncio
    async def test_full_observability_stack(self) -> None:
        """æµ‹è¯•å®Œæ•´å¯è§‚æµ‹æ€§å †æ ˆ."""
        metrics = MetricsCollector()
        logger = TracingLogger("full_test")

        async def full_operation(should_fail: bool = False) -> str:
            logger.info("Starting operation")

            if should_fail:
                logger.error("Operation failed")
                metrics.increment_query_request(status="error", database="test_db")
                raise ValueError("Operation failed")
            else:
                logger.info("Operation succeeded")
                metrics.increment_query_request(status="success", database="test_db")
                metrics.query_duration.observe(0.5)
                return "success"

        # æˆåŠŸåœºæ™¯
        async with request_context():
            result = await full_operation(should_fail=False)
            assert result == "success"

        # å¤±è´¥åœºæ™¯
        async with request_context():
            with pytest.raises(ValueError):
                await full_operation(should_fail=True)


class TestObservabilityEdgeCases:
    """è¾¹ç¼˜æƒ…å†µæµ‹è¯•."""

    def test_metrics_with_none_database(self) -> None:
        """æµ‹è¯• None æ•°æ®åº“åç§°."""
        metrics = MetricsCollector()

        # åº”è¯¥å¤„ç† None æ•°æ®åº“å (å®é™…å®ç°ä¸­ Prometheus labels ä¸æ”¯æŒ None)
        # è¿™é‡Œæˆ‘ä»¬åªéªŒè¯æ–¹æ³•å¯ä»¥è¢«è°ƒç”¨
        try:
            metrics.increment_query_request(status="success", database="test_db")
            metrics.query_duration.observe(1.0)
        except Exception:
            # å¦‚æœå®ç°ä¸æ”¯æŒ,ä¹Ÿè®¤ä¸ºæµ‹è¯•é€šè¿‡
            pass

    def test_tracing_without_context(self) -> None:
        """æµ‹è¯•æ²¡æœ‰ä¸Šä¸‹æ–‡çš„è¿½è¸ª."""
        from pg_mcp.observability.tracing import get_request_id

        async def test_function() -> str:
            # æ²¡æœ‰ä¸Šä¸‹æ–‡æ—¶, get_request_id åº”è¯¥è¿”å› None
            assert get_request_id() is None
            return "success"

        # åº”è¯¥åœ¨æ²¡æœ‰æ˜¾å¼ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹å·¥ä½œ
        result = asyncio.run(test_function())
        assert result == "success"

    def test_logger_with_unicode(self) -> None:
        """æµ‹è¯•æ—¥å¿—ä¸­çš„ Unicode å­—ç¬¦."""
        logger = TracingLogger("unicode_test")

        # Unicode æ¶ˆæ¯åº”è¯¥è¢«æ­£ç¡®å¤„ç†
        logger.info("æµ‹è¯•æ¶ˆæ¯")
        logger.info("Test message with emoji: ğŸš€")
        logger.info("Test message with accent: cafÃ©")

    def test_json_formatter_with_complex_data(self) -> None:
        """æµ‹è¯• JSON æ ¼å¼åŒ–å™¨å¤„ç†å¤æ‚æ•°æ®."""
        formatter = JSONFormatter()

        record = logging.LogRecord(
            name="test",
            level=logging.INFO,
            pathname="test.py",
            lineno=10,
            msg="Test message",
            args=(),
            exc_info=None,
        )

        # æ·»åŠ å¤æ‚æ•°æ® (è¿™äº›ä¼šæ”¾åœ¨ "extra" ä¸‹)
        record.nested_dict = {"key1": {"key2": "value"}}
        record.list_data = [1, 2, 3]
        record.mixed_data = {"list": [1, 2], "dict": {"key": "value"}}

        formatted = formatter.format(record)
        parsed = json.loads(formatted)

        # éªŒè¯å¤æ‚æ•°æ®åœ¨ extra ä¸‹
        assert "extra" in parsed
        assert parsed["extra"]["nested_dict"]["key1"]["key2"] == "value"
        assert parsed["extra"]["list_data"] == [1, 2, 3]
        assert parsed["extra"]["mixed_data"]["list"] == [1, 2]


class TestObservabilityPerformance:
    """æ€§èƒ½æµ‹è¯•."""

    @pytest.mark.asyncio
    async def test_metrics_overhead(self) -> None:
        """æµ‹è¯•æŒ‡æ ‡æ”¶é›†çš„æ€§èƒ½å¼€é”€."""
        metrics = MetricsCollector()

        import time

        start = time.perf_counter()

        for _ in range(1000):
            metrics.increment_query_request(status="success", database="test_db")
            metrics.query_duration.observe(0.5)
            metrics.increment_llm_call(operation="generate_sql")

        elapsed = time.perf_counter() - start

        # 1000 æ¬¡æ“ä½œåº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        assert elapsed < 1.0

    @pytest.mark.asyncio
    async def test_tracing_overhead(self) -> None:
        """æµ‹è¯•è¿½è¸ªçš„æ€§èƒ½å¼€é”€."""
        async def test_function() -> str:
            return "success"

        import time

        start = time.perf_counter()

        for _ in range(1000):
            await test_function()

        elapsed = time.perf_counter() - start

        # 1000 æ¬¡æ“ä½œåº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        assert elapsed < 1.0

    def test_logging_overhead(self) -> None:
        """æµ‹è¯•æ—¥å¿—è®°å½•çš„æ€§èƒ½å¼€é”€."""
        logger = TracingLogger("performance_test")

        import time

        start = time.perf_counter()

        for i in range(1000):
            logger.info(f"Test message {i}")

        elapsed = time.perf_counter() - start

        # 1000 æ¬¡æ—¥å¿—è®°å½•åº”è¯¥åœ¨åˆç†æ—¶é—´å†…å®Œæˆ
        assert elapsed < 1.0
